{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Split-Classify on Epson Workforce Scanner PDFs\n",
    "\n",
    "This notebook tests the **split-classify** pipeline on real scanned PDFs from the\n",
    "Epson Workforce scanner. These PDFs often contain multiple document types per file\n",
    "(receipts, bills, letters, etc.) from a single scanning session.\n",
    "\n",
    "Pipeline: **Ingest** → **Parse** → **Split & Classify** → **Inspect results**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import sys, os\n",
    "\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_ROOT)\n",
    "os.chdir(PROJECT_ROOT)\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(os.path.join(PROJECT_ROOT, \".env\"))\n",
    "print(f\"CWD: {os.getcwd()}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from lightodm import MongoConnection\n",
    "\n",
    "conn = MongoConnection()\n",
    "await conn.get_async_client()\n",
    "print(\"Connected to MongoDB\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set the scanner directory and sample size. PDFs are randomly selected with a fixed seed for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "# Directory containing scanned PDFs from Epson Workforce\n",
    "WORKFORCE_DIR = Path.home() / \"OneDrive/Documents/SCANS/epson/workforce\"\n",
    "SAMPLE_SIZE = 20\n",
    "TAG = \"split-classify-test\"\n",
    "SEED = 42\n",
    "\n",
    "assert WORKFORCE_DIR.is_dir(), f\"Directory not found: {WORKFORCE_DIR}\"\n",
    "\n",
    "# Discover all PDFs and sample\n",
    "all_pdfs = sorted(WORKFORCE_DIR.glob(\"*.pdf\"))\n",
    "print(f\"Found {len(all_pdfs)} PDFs in {WORKFORCE_DIR}\")\n",
    "\n",
    "rng = random.Random(SEED)\n",
    "sample_pdfs = rng.sample(all_pdfs, min(SAMPLE_SIZE, len(all_pdfs)))\n",
    "print(f\"Selected {len(sample_pdfs)} PDFs for testing:\")\n",
    "for p in sample_pdfs:\n",
    "    print(f\"  {p.name}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingest + Parse\n",
    "\n",
    "Ingest the sample PDFs as external documents (skipping already-ingested ones),\n",
    "then parse any unparsed documents."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from mydocs.models import Document, DocumentPage, StorageModeEnum\n",
    "from mydocs.parsing.pipeline import ingest_files, parse_document\n",
    "\n",
    "# Ingest sample PDFs (skips already-ingested files)\n",
    "documents, skipped = await ingest_files(\n",
    "    source=[str(p) for p in sample_pdfs],\n",
    "    storage_mode=StorageModeEnum.EXTERNAL,\n",
    "    tags=[TAG],\n",
    ")\n",
    "\n",
    "print(f\"Ingested: {len(documents)}, Skipped (already exist): {len(skipped)}\")\n",
    "\n",
    "# Collect all document IDs (both new and existing)\n",
    "doc_ids = [str(d.id) for d in documents]\n",
    "\n",
    "# Look up already-existing documents that were skipped\n",
    "for pdf_path in sample_pdfs:\n",
    "    abs_path = str(pdf_path.resolve())\n",
    "    existing = await Document.afind({\"original_path\": abs_path})\n",
    "    for ex in existing:\n",
    "        if str(ex.id) not in doc_ids:\n",
    "            doc_ids.append(str(ex.id))\n",
    "\n",
    "print(f\"Total documents to process: {len(doc_ids)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Parse any unparsed documents\n",
    "parsed_count = 0\n",
    "for doc_id in doc_ids:\n",
    "    doc = await Document.aget(doc_id)\n",
    "    if doc and doc.status != \"parsed\":\n",
    "        try:\n",
    "            await parse_document(doc_id)\n",
    "            parsed_count += 1\n",
    "            print(f\"  Parsed: {doc.original_file_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  FAILED: {doc.original_file_name}: {e}\")\n",
    "\n",
    "print(f\"\\nNewly parsed: {parsed_count}, Already parsed: {len(doc_ids) - parsed_count}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split & Classify\n",
    "\n",
    "Load the split-classify prompt config and run `split_and_classify()` on each document."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from mydocs.extracting.prompt_utils import get_split_classify_prompt\n",
    "from mydocs.extracting.splitter import split_and_classify\n",
    "from mydocs.extracting.models import SplitClassifyResult\n",
    "\n",
    "# Load prompt config\n",
    "prompt_config = get_split_classify_prompt(\"generic\")\n",
    "print(f\"Prompt config loaded: {prompt_config.name}\")\n",
    "print(f\"  model: {prompt_config.model}\")\n",
    "print(f\"  batch_size: {prompt_config.batch_size}\")\n",
    "print(f\"  overlap_factor: {prompt_config.overlap_factor}\")\n",
    "print(f\"  output_schema: {prompt_config.output_schema}\")\n",
    "\n",
    "# Run split-classify on each document\n",
    "results: dict[str, SplitClassifyResult] = {}\n",
    "\n",
    "for doc_id in doc_ids:\n",
    "    doc = await Document.aget(doc_id)\n",
    "    if not doc:\n",
    "        print(f\"  Document {doc_id} not found, skipping\")\n",
    "        continue\n",
    "    try:\n",
    "        result = await split_and_classify(\n",
    "            document_id=doc_id,\n",
    "            prompt_config=prompt_config,\n",
    "            case_type=\"generic\",\n",
    "        )\n",
    "        results[doc_id] = result\n",
    "        seg_summary = \", \".join(\n",
    "            f\"{s.document_type}(pp{s.page_numbers[0]}-{s.page_numbers[-1]})\"\n",
    "            for s in result.segments\n",
    "        )\n",
    "        print(f\"  {doc.original_file_name}: {len(result.segments)} segments — {seg_summary}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  FAILED {doc.original_file_name}: {e}\")\n",
    "\n",
    "print(f\"\\nCompleted: {len(results)}/{len(doc_ids)} documents\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Summary\n",
    "\n",
    "Aggregate statistics: document type distribution, multi-document PDF counts."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from collections import Counter\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Aggregate stats\n",
    "type_counter = Counter()\n",
    "multi_doc_count = 0\n",
    "total_segments = 0\n",
    "\n",
    "for doc_id, result in results.items():\n",
    "    total_segments += len(result.segments)\n",
    "    if len(result.segments) > 1:\n",
    "        multi_doc_count += 1\n",
    "    for seg in result.segments:\n",
    "        type_counter[seg.document_type] += 1\n",
    "\n",
    "# Summary table\n",
    "rows = \"\"\n",
    "for doc_type, count in type_counter.most_common():\n",
    "    pct = count / total_segments * 100 if total_segments else 0\n",
    "    rows += f\"<tr><td>{doc_type}</td><td>{count}</td><td>{pct:.1f}%</td></tr>\\n\"\n",
    "\n",
    "html = f\"\"\"\n",
    "<h3>Split-Classify Results</h3>\n",
    "<p><b>Documents processed:</b> {len(results)}</p>\n",
    "<p><b>Total segments:</b> {total_segments}</p>\n",
    "<p><b>Multi-document PDFs:</b> {multi_doc_count} ({multi_doc_count/len(results)*100:.0f}% of processed)</p>\n",
    "<table border='1' cellpadding='4'>\n",
    "<tr><th>Document Type</th><th>Count</th><th>%</th></tr>\n",
    "{rows}</table>\n",
    "\"\"\"\n",
    "display(HTML(html))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "Render PDF pages with colored borders and labels for each classified segment."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "try:\n",
    "    import fitz  # PyMuPDF\n",
    "except ImportError:\n",
    "    raise ImportError(\"Install PyMuPDF: pip install pymupdf\")\n",
    "\n",
    "from IPython.display import display, Image as IPImage\n",
    "\n",
    "# Color palette per document type\n",
    "TYPE_COLORS = {\n",
    "    \"receipt\":        (0.0, 0.6, 0.0),    # green\n",
    "    \"bill\":           (0.0, 0.4, 0.8),    # blue\n",
    "    \"invoice\":        (0.8, 0.4, 0.0),    # orange\n",
    "    \"letter\":         (0.6, 0.0, 0.8),    # purple\n",
    "    \"form\":           (0.8, 0.0, 0.4),    # magenta\n",
    "    \"certificate\":    (0.0, 0.7, 0.7),    # teal\n",
    "    \"contract\":       (0.5, 0.5, 0.0),    # olive\n",
    "    \"id_document\":    (0.8, 0.0, 0.0),    # red\n",
    "    \"bank_statement\": (0.3, 0.3, 0.8),    # slate blue\n",
    "    \"other\":          (0.5, 0.5, 0.5),    # gray\n",
    "}\n",
    "\n",
    "def get_type_color(doc_type: str) -> tuple:\n",
    "    return TYPE_COLORS.get(doc_type, (0.5, 0.5, 0.5))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from mydocs.extracting.models import SplitSegment\n",
    "\n",
    "\n",
    "def render_document_segments(\n",
    "    pdf_path: str,\n",
    "    segments: list[SplitSegment],\n",
    "    dpi: int = 120,\n",
    ") -> list[bytes]:\n",
    "    \"\"\"Render PDF pages with colored borders and labels per segment.\n",
    "\n",
    "    Returns list of PNG bytes, one per page.\n",
    "    \"\"\"\n",
    "    # Build page_number -> segment mapping\n",
    "    page_to_segment: dict[int, SplitSegment] = {}\n",
    "    for seg in segments:\n",
    "        for pn in seg.page_numbers:\n",
    "            page_to_segment[pn] = seg\n",
    "\n",
    "    pdf = fitz.open(pdf_path)\n",
    "    images = []\n",
    "\n",
    "    for page_idx in range(len(pdf)):\n",
    "        page = pdf[page_idx]\n",
    "        page_num = page_idx + 1  # 1-based\n",
    "        seg = page_to_segment.get(page_num)\n",
    "\n",
    "        if seg:\n",
    "            color = get_type_color(seg.document_type)\n",
    "            # Draw a thick border around the entire page\n",
    "            rect = page.rect\n",
    "            border = fitz.Rect(rect.x0 + 2, rect.y0 + 2, rect.x1 - 2, rect.y1 - 2)\n",
    "            page.draw_rect(border, color=color, width=4)\n",
    "\n",
    "            # Label in top-left corner\n",
    "            label = f\"[{seg.document_type}] pp {seg.page_numbers[0]}-{seg.page_numbers[-1]}\"\n",
    "            # Draw a filled background for the label\n",
    "            label_rect = fitz.Rect(rect.x0 + 4, rect.y0 + 4, rect.x0 + 250, rect.y0 + 22)\n",
    "            page.draw_rect(label_rect, color=color, fill=color)\n",
    "            page.insert_text(\n",
    "                fitz.Point(rect.x0 + 6, rect.y0 + 18),\n",
    "                label,\n",
    "                fontsize=10,\n",
    "                color=(1, 1, 1),  # white text on colored background\n",
    "            )\n",
    "\n",
    "        mat = fitz.Matrix(dpi / 72, dpi / 72)\n",
    "        pix = page.get_pixmap(matrix=mat)\n",
    "        images.append(pix.tobytes(\"png\"))\n",
    "\n",
    "    pdf.close()\n",
    "    return images"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Display rendered pages for the first 5 documents\n",
    "MAX_DISPLAY = 5\n",
    "\n",
    "for i, (doc_id, result) in enumerate(results.items()):\n",
    "    if i >= MAX_DISPLAY:\n",
    "        break\n",
    "\n",
    "    doc = await Document.aget(doc_id)\n",
    "    if not doc:\n",
    "        continue\n",
    "\n",
    "    pdf_path = doc.managed_path or doc.original_path\n",
    "    if not pdf_path or not os.path.isfile(pdf_path):\n",
    "        print(f\"PDF not found for {doc.original_file_name}\")\n",
    "        continue\n",
    "\n",
    "    seg_summary = \", \".join(\n",
    "        f\"{s.document_type}(pp{s.page_numbers[0]}-{s.page_numbers[-1]})\"\n",
    "        for s in result.segments\n",
    "    )\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{doc.original_file_name}: {seg_summary}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    images = render_document_segments(pdf_path, result.segments)\n",
    "    for img_bytes in images:\n",
    "        display(IPImage(data=img_bytes))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run on Any File\n",
    "\n",
    "Set `TEST_PDF_PATH` to any PDF and run the full pipeline: ingest → parse → split-classify → render."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Set this to any PDF path\n",
    "TEST_PDF_PATH = str(WORKFORCE_DIR / \"Receipt_20260129_0002.pdf\")\n",
    "assert os.path.isfile(TEST_PDF_PATH), f\"File not found: {TEST_PDF_PATH}\"\n",
    "\n",
    "# Ingest (skip if already exists)\n",
    "test_docs, test_skipped = await ingest_files(\n",
    "    source=[TEST_PDF_PATH],\n",
    "    storage_mode=StorageModeEnum.EXTERNAL,\n",
    "    tags=[TAG],\n",
    ")\n",
    "if test_docs:\n",
    "    test_doc = test_docs[0]\n",
    "elif test_skipped:\n",
    "    existing = await Document.afind({\"original_path\": os.path.abspath(TEST_PDF_PATH)})\n",
    "    test_doc = existing[0]\n",
    "else:\n",
    "    raise RuntimeError(\"Ingest returned no documents and no skipped entries\")\n",
    "\n",
    "TEST_DOC_ID = str(test_doc.id)\n",
    "print(f\"Document: {test_doc.original_file_name} (id={TEST_DOC_ID})\")\n",
    "\n",
    "# Parse if needed\n",
    "if test_doc.status != \"parsed\":\n",
    "    test_doc = await parse_document(TEST_DOC_ID)\n",
    "    print(f\"Parsed: {test_doc.status}\")\n",
    "\n",
    "# Split-classify\n",
    "test_result = await split_and_classify(\n",
    "    document_id=TEST_DOC_ID,\n",
    "    prompt_config=prompt_config,\n",
    "    case_type=\"generic\",\n",
    ")\n",
    "\n",
    "for seg in test_result.segments:\n",
    "    print(f\"  {seg.document_type}: pages {seg.page_numbers}\")\n",
    "\n",
    "# Render\n",
    "test_pdf_path = test_doc.managed_path or test_doc.original_path\n",
    "images = render_document_segments(test_pdf_path, test_result.segments)\n",
    "for img in images:\n",
    "    display(IPImage(data=img))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SubDocument Inspection\n",
    "\n",
    "Reload the document and inspect the persisted `SubDocument` objects."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Inspect persisted subdocuments on any processed document\n",
    "# Change this to any doc_id from the results\n",
    "INSPECT_DOC_ID = TEST_DOC_ID\n",
    "\n",
    "doc = await Document.aget(INSPECT_DOC_ID)\n",
    "if doc and doc.subdocuments:\n",
    "    print(f\"Document: {doc.original_file_name}\")\n",
    "    print(f\"SubDocuments: {len(doc.subdocuments)}\\n\")\n",
    "    for sd in doc.subdocuments:\n",
    "        page_nums = [pr.page_number for pr in sd.page_refs]\n",
    "        print(f\"  id: {sd.id}\")\n",
    "        print(f\"  case_type: {sd.case_type}\")\n",
    "        print(f\"  document_type: {sd.document_type}\")\n",
    "        print(f\"  pages: {page_nums}\")\n",
    "        print(f\"  created_at: {sd.created_at}\")\n",
    "        print()\n",
    "else:\n",
    "    print(f\"No subdocuments found on document {INSPECT_DOC_ID}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "Uncomment to delete test documents and associated data from MongoDB."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# # Cleanup: remove all documents tagged with the test tag\n",
    "# from mydocs.extracting.models import FieldResultRecord\n",
    "#\n",
    "# tagged_docs = await Document.afind({\"tags\": TAG})\n",
    "# for d in tagged_docs:\n",
    "#     did = str(d.id)\n",
    "#     await FieldResultRecord.adelete_many({\"document_id\": did})\n",
    "#     await DocumentPage.adelete_many({\"document_id\": did})\n",
    "#     await Document.adelete_one({\"_id\": did})\n",
    "#     print(f\"Deleted: {d.original_file_name} ({did})\")\n",
    "#\n",
    "# print(f\"\\nCleaned up {len(tagged_docs)} documents\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
